{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base BERT-MLP pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import create_word_lists, tidy_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/corpus_data.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "data = data[\"records\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_transcripts = [entry[\"human_transcript\"] for entry in data]\n",
    "stt_transcripts = [entry[\"stt_transcript\"] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_words, stt_words, word_labels, word_grams, word_sems = create_word_lists(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt_transcripts, stt_words, word_labels, word_grams, word_sems = tidy_sentence_length(\n",
    "    stt_transcripts, stt_words, word_labels, word_grams, word_sems\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE START\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(map(len, word_labels))\n",
    "padded_labels = [row + [False] * (max_length - len(row)) for row in word_labels]\n",
    "padded_labels = np.array(padded_labels)\n",
    "stat_labels = np.any(padded_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(stt_transcripts)))\n",
    "tr_indices, te_indices = train_test_split(\n",
    "    indices, test_size=0.2, random_state=0, shuffle=True, stratify=stat_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_train = itemgetter(*tr_indices)\n",
    "extract_test = itemgetter(*te_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stt_transcripts = extract_train(stt_transcripts)\n",
    "tr_stt_words = extract_train(stt_words)\n",
    "\n",
    "tr_word_labels = extract_train(word_labels)\n",
    "tr_word_grams = extract_train(word_grams)\n",
    "tr_word_sems = extract_train(word_sems)\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "te_stt_transcripts = extract_test(stt_transcripts)\n",
    "te_stt_words = extract_test(stt_words)\n",
    "\n",
    "te_word_labels = extract_test(word_labels)\n",
    "te_word_grams = extract_test(word_grams)\n",
    "te_word_sems = extract_test(word_sems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_encoder import encode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model_bert = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "model_bert.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "../../tr_stt_vectors = []\n",
    "te_stt_vectors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, words in zip(tr_stt_transcripts, tr_stt_words):\n",
    "    tr_stt_vectors.append(encode_sentence(sentence, words, model_bert, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, words in zip(te_stt_transcripts, te_stt_words):\n",
    "    te_stt_vectors.append(encode_sentence(sentence, words, model_bert, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tensor = torch.vstack(tr_stt_vectors)\n",
    "tr_label_tensor = torch.tensor(\n",
    "    [int(element) for sublist in tr_word_labels for element in sublist]\n",
    ")\n",
    "tr_grams_tensor = torch.tensor(\n",
    "    [int(element) for sublist in tr_word_grams for element in sublist]\n",
    ")\n",
    "tr_sems_tensor = torch.tensor(\n",
    "    [int(element) for sublist in tr_word_sems for element in sublist]\n",
    ")\n",
    "\n",
    "\n",
    "te_tensor = torch.vstack(te_stt_vectors)\n",
    "te_label_tensor = torch.tensor(\n",
    "    [int(element) for sublist in te_word_labels for element in sublist]\n",
    ")\n",
    "te_grams_tensor = torch.tensor(\n",
    "    [int(element) for sublist in te_word_grams for element in sublist]\n",
    ")\n",
    "te_sems_tensor = torch.tensor(\n",
    "    [int(element) for sublist in te_word_sems for element in sublist]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP, cross_validate_model, train_model, calc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_options = [10, 25, 20]\n",
    "hidden_layers_options = [1, 4, 8, 12, 16]\n",
    "neurons_per_layer_options = [32, 64, 128, 256]\n",
    "learning_rate_options = [1e-3, 1e-4, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = itertools.product(\n",
    "    epochs_options,\n",
    "    hidden_layers_options,\n",
    "    neurons_per_layer_options,\n",
    "    learning_rate_options,\n",
    ")\n",
    "parameter_combinations = list(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float(\"inf\")\n",
    "best_params = None\n",
    "\n",
    "features = tr_tensor\n",
    "labels = tr_label_tensor\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/180 [00:00<?, ?it/s]/home/dyco/EPFL/SEMESTAR_1/ML/ml-project-2-machinesoflearning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [2:52:49<00:00, 57.61s/it]   \n"
     ]
    }
   ],
   "source": [
    "for combination in tqdm(parameter_combinations):\n",
    "    epochs, hidden_layers, neurons_per_layer, learning_rate = combination\n",
    "\n",
    "    model = MLP(features.shape[1], hidden_layers, neurons_per_layer).to(torch_device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    tr_loss, tr_loss_std, te_loss, te_loss_std = cross_validate_model(\n",
    "        model,\n",
    "        features,\n",
    "        labels,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        splitter,\n",
    "        n_epochs=epochs,\n",
    "        num_workers=0,\n",
    "        device=torch_device,\n",
    "    )\n",
    "\n",
    "    values_to_add = [\n",
    "        epochs,\n",
    "        hidden_layers,\n",
    "        neurons_per_layer,\n",
    "        learning_rate,\n",
    "        tr_loss,\n",
    "        tr_loss_std,\n",
    "        te_loss,\n",
    "        te_loss_std,\n",
    "    ]\n",
    "\n",
    "    # Add preliminary data to dataframe\n",
    "    grid_search_data.append(values_to_add)\n",
    "\n",
    "    if te_loss < best_loss:\n",
    "        best_loss = te_loss\n",
    "        best_params = combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"../outputs/BERT/\"\n",
    "columns = [\n",
    "    \"epochs\",\n",
    "    \"hidden_layers\",\n",
    "    \"neurons_per_layer\",\n",
    "    \"learning_rate\",\n",
    "    \"tr_loss\",\n",
    "    \"tr_loss_std\",\n",
    "    \"te_loss\",\n",
    "    \"te_loss_std\",\n",
    "]\n",
    "gs_frame = pd.DataFrame(grid_search_data, columns=columns)\n",
    "gs_frame.to_csv(os.path.join(out_path, \"gs_data_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import STTDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = STTDataset(tr_tensor, tr_label_tensor)\n",
    "num_workers = 0  # This works fastest on my machine\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=128, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "\n",
    "epochs, hidden_layers, neurons_per_layer, learning_rate = best_params\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "model = MLP(features.shape[1], hidden_layers, neurons_per_layer).to(torch_device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010613417972827239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    model, criterion, optimizer, train_loader, n_epochs=epochs, device=torch_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = STTDataset(te_tensor, te_label_tensor)\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size=len(test_data), shuffle=True, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(torch_device), labels.to(torch_device)\n",
    "        pred = model(inputs)\n",
    "        pred = torch.squeeze(pred, dim=1)\n",
    "        loss = criterion(pred, labels.to(torch.float)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = calc_stats(pred, te_label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    [[loss, accuracy, precision, recall, f1]],\n",
    "    columns=[\"loss\", \"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    ")\n",
    "results.to_csv(os.path.join(out_path, \"bert_test.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
