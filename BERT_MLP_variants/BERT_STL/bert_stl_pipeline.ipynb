{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use second-to-last layer of BERT encoder as word representations to be inputted to MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import create_word_lists, tidy_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/corpus_data.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "data = data[\"records\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_transcripts = [entry[\"human_transcript\"] for entry in data]\n",
    "stt_transcripts = [entry[\"stt_transcript\"] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_words, stt_words, word_labels, word_grams, word_sems = create_word_lists(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt_transcripts, stt_words, word_labels, word_grams, word_sems = tidy_sentence_length(\n",
    "    stt_transcripts, stt_words, word_labels, word_grams, word_sems\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE START\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(map(len, word_labels))\n",
    "padded_labels = [row + [False] * (max_length - len(row)) for row in word_labels]\n",
    "padded_labels = np.array(padded_labels)\n",
    "stat_labels = np.any(padded_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(stt_transcripts)))\n",
    "tr_indices, te_indices = train_test_split(\n",
    "    indices, test_size=0.2, random_state=0, shuffle=True, stratify=stat_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_train = itemgetter(*tr_indices)\n",
    "extract_test = itemgetter(*te_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stt_transcripts = extract_train(stt_transcripts)\n",
    "tr_stt_words = extract_train(stt_words)\n",
    "\n",
    "tr_word_labels = extract_train(word_labels)\n",
    "tr_word_grams = extract_train(word_grams)\n",
    "tr_word_sems = extract_train(word_sems)\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "te_stt_transcripts = extract_test(stt_transcripts)\n",
    "te_stt_words = extract_test(stt_words)\n",
    "\n",
    "te_word_labels = extract_test(word_labels)\n",
    "te_word_grams = extract_test(word_grams)\n",
    "te_word_sems = extract_test(word_sems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyco/EPFL/SEMESTAR_1/ML/ml-project-2-machinesoflearning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_encoder import encode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model_bert = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "model_bert.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stt_vectors = []\n",
    "te_stt_vectors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the corpus, with `vectorization=\"stl\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, words in zip(tr_stt_transcripts, tr_stt_words):\n",
    "    tr_stt_vectors.append(\n",
    "        encode_sentence(sentence, words, model_bert, tokenizer, vectorization=\"stl\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, words in zip(te_stt_transcripts, te_stt_words):\n",
    "    te_stt_vectors.append(\n",
    "        encode_sentence(sentence, words, model_bert, tokenizer, vectorization=\"stl\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tensor = torch.vstack(tr_stt_vectors)\n",
    "tr_label_tensor = torch.tensor(\n",
    "    [int(element) for sublist in tr_word_labels for element in sublist]\n",
    ")\n",
    "tr_grams_tensor = torch.tensor(\n",
    "    [int(element) for sublist in tr_word_grams for element in sublist]\n",
    ")\n",
    "tr_sems_tensor = torch.tensor(\n",
    "    [int(element) for sublist in tr_word_sems for element in sublist]\n",
    ")\n",
    "\n",
    "\n",
    "te_tensor = torch.vstack(te_stt_vectors)\n",
    "te_label_tensor = torch.tensor(\n",
    "    [int(element) for sublist in te_word_labels for element in sublist]\n",
    ")\n",
    "te_grams_tensor = torch.tensor(\n",
    "    [int(element) for sublist in te_word_grams for element in sublist]\n",
    ")\n",
    "te_sems_tensor = torch.tensor(\n",
    "    [int(element) for sublist in te_word_sems for element in sublist]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP, cross_validate_model, train_model, calc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = (20, 1, 256, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import STTDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = STTDataset(tr_tensor, tr_label_tensor)\n",
    "num_workers = 0  # This works fastest on my machine\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=128, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "\n",
    "epochs, hidden_layers, neurons_per_layer, learning_rate = best_params\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "model = MLP(tr_tensor.shape[1], hidden_layers, neurons_per_layer).to(torch_device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040139796198024165"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    model, criterion, optimizer, train_loader, n_epochs=epochs, device=torch_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = STTDataset(te_tensor, te_label_tensor)\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size=len(test_data), shuffle=True, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(torch_device), labels.to(torch_device)\n",
    "        pred = model(inputs)\n",
    "        pred = torch.squeeze(pred, dim=1)\n",
    "        loss = criterion(pred, labels.to(torch.float)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = calc_stats(pred, te_label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019607843137254905"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    [[loss, accuracy, precision, recall, f1]],\n",
    "    columns=[\"loss\", \"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    ")\n",
    "results.to_csv(os.path.join(out_path, \"results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_te_words = [element for sublist in te_stt_words for element in sublist]\n",
    "all_te_labels = [element for sublist in te_word_labels for element in sublist]\n",
    "all_te_predictions = (pred.to(\"cpu\").numpy().flatten() > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_words = []\n",
    "german_predictions = []\n",
    "for i in range(len(all_te_words)):\n",
    "    if all_te_labels[i]:\n",
    "        german_words.append(all_te_words[i])\n",
    "        german_predictions.append(all_te_predictions[i])\n",
    "\n",
    "predicted_labels = pd.DataFrame(\n",
    "    {\"word\": german_words, \"prediction\": german_predictions}\n",
    ")\n",
    "predicted_labels.to_csv(os.path.join(out_path, \"word_labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bilde</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>east</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>sachin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>can</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>at</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>walk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>chrome</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>just</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>im</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>bonbons</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>this</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>howls</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>wot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>top</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>staaken</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>with</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  prediction\n",
       "1      bilde           1\n",
       "58      east           1\n",
       "135      tok           1\n",
       "384   sachin           1\n",
       "291      can           1\n",
       "0        ash           0\n",
       "265       at           0\n",
       "273     walk           0\n",
       "272      the           0\n",
       "271      the           0\n",
       "270   chrome           0\n",
       "269     just           0\n",
       "268       im           0\n",
       "267  bonbons           0\n",
       "266     this           0\n",
       "263    howls           0\n",
       "264      wot           0\n",
       "275      top           0\n",
       "262  staaken           0\n",
       "261     with           0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels.sort_values(by=\"prediction\", ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
