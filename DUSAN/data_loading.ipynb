{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'corpus_data.json')) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['records']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 62305 words in 6723 from STT transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_transcripts = [entry['human_transcript'] for entry in data]\n",
    "stt_transcripts   = [entry['stt_transcript'] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_words = []\n",
    "stt_words = []\n",
    "word_classes = []\n",
    "\n",
    "for entry in data:\n",
    "    entry_stt_words = []\n",
    "    entry_hum_words = []\n",
    "    entry_labels = []\n",
    "    entry_classes = []\n",
    "\n",
    "    for word in entry['words']:\n",
    "        humw = word['human_word']\n",
    "        sttw = word['stt_word']\n",
    "\n",
    "        # if either stt or human transcript don't contain a word, skip it\n",
    "        # TODO: we migh want to split the phrases if we use this for features\n",
    "        if re.sub(r'@.', '', humw)=='' or sttw=='':\n",
    "            continue\n",
    "        \n",
    "        # if it is a german word/phrase, annotate it\n",
    "        if '@g' in humw:\n",
    "            entry_hum_words.append(re.sub(r'@.', '', humw))\n",
    "            entry_classes.append(1)\n",
    "\n",
    "        # if the word contains another type of a mistake, just remove annotations - we don't care\n",
    "        # TODO: we can also add different markings for each type of mistake for the learning algorithm later\n",
    "        elif '@' in humw:\n",
    "            entry_hum_words.append(re.sub(r'@.', '', humw))\n",
    "            entry_classes.append(0)\n",
    "\n",
    "        # otherwise, just add the word\n",
    "        else:\n",
    "            entry_hum_words.append(humw)\n",
    "            entry_classes.append(0)\n",
    "\n",
    "        # stt word don't have to be cleaned\n",
    "        entry_stt_words.append(word['stt_word'])\n",
    "\n",
    "    human_words.append(entry_hum_words)\n",
    "    stt_words.append(entry_stt_words)\n",
    "    word_classes.append(entry_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool i  coo like\n",
      "deine lustigste  an lusting\n",
      "cold have  call that\n",
      "grandmother there  grand motor where\n",
      "book in  book in\n",
      "there is there   thirst where\n",
      "ter with  to rift in\n",
      "einkaufszentrum there s   uncas centrum verse\n",
      "thing but  thing but\n",
      "i am from   ive rome\n",
      "the strawberry cake   drapery kick\n",
      "have pancakes  happen case\n",
      "candy cates  can indicate\n",
      "doesn t  does not\n",
      "anything else  a saga\n",
      "chocolate chewing  tugler tin\n",
      "a nice  an it\n",
      "one centimeter  once timet\n",
      "or jonglieren  in what\n",
      "got the  go to\n",
      "sind getrennt  singe trent\n",
      "yeah my  am i\n",
      "she is  she is\n",
      "reinfa one 4   ranand 0\n",
      "but it  but it\n",
      "come be to   compete is\n",
      "a sun cream   some tree\n",
      "cola or  coal for\n",
      "it s cold   is called\n",
      "it s blue   is clue\n",
      "eh eine  a iies\n",
      "we draw  which rage\n",
      "w reiten wiff   writen with\n",
      "your cold  you are could\n",
      "my picture  a romantic there\n",
      "vorha nge are   for hanging or\n",
      "play this als   ladies as\n",
      "i love  il of\n",
      "eisba r  ice bear\n",
      "eisba r  ice bear\n",
      "eisba r  ice bear\n",
      "eisba r  ice pear\n",
      "eisba r  ice care\n",
      "it is  i days\n",
      "lollipop do  lowly popo\n",
      "is sport  its part\n",
      "do not pretending   unpretending the\n",
      "princess peach  prince speech\n",
      "don t  do not\n",
      "candies it s   candy is\n",
      "black stripe  lacked ripe\n",
      "weg also  vegas the\n",
      "werfen sondern  reference on the\n",
      "es hat schmutz   such mute\n",
      "i am walking   and blank\n",
      "is it  you said\n",
      "i am running with    ever 0\n",
      "i am sleeping   asleep in\n",
      "welcome bye  well come by\n",
      "zwei achsi  like see\n",
      "don t  do not\n",
      "es tut  i stood\n",
      "when you  we onpoyou\n",
      "is actually  is actually\n",
      "don t  do not\n",
      "smells like  is mislike\n",
      "i do not   item now\n",
      "in the  in the\n",
      "a one 4 berrumpelt    over romped\n",
      "don t  do not\n",
      "don t  do not\n",
      "go to  go to\n",
      "another friend  a autorfriend\n",
      "my name  mine am\n",
      "my love  mail of\n",
      "at home  a to\n",
      "offene haare  of nahara\n",
      "my friend  my friend\n",
      "donut no  do not not\n",
      "muffin have  must in half\n",
      "flag then  flake than\n",
      "eisba r  eyes were\n",
      "eisbla cke g   ice blocks\n",
      "eisba r  ice pear\n",
      "also so  a sushi\n",
      "biene or  p 0\n",
      "i have  i have\n",
      "a spindel  ash bilde\n",
      "woman have  to overhanded\n",
      "lots of  lots of\n",
      "verspielter und ja   fasbilta ronda\n",
      "would the  will that\n",
      "then also  the naruto\n",
      "and things  and things\n",
      "like i  very kylie\n",
      "candy rainy  can drain\n",
      "your right  you write\n",
      "a dunkelblau  duncle blow\n",
      "10 vor 12   10412 okay\n",
      "is my turn   smarter and\n",
      "your ort wo   our otho\n",
      "students and  students and\n",
      "koffein drin  coffer in dren\n",
      "also na  is alternate\n",
      "orange oder  or ranch order\n",
      "bottom oder  bad motor\n",
      "don t  do not\n",
      "the tricots  that i cose\n",
      "auf deutsch  advise okay\n",
      "pippi langstrumpf  pippylangstroom an\n",
      "sitzsack are  sit ssuck or\n",
      "don t  do not\n",
      "walking is  walked in i\n",
      "bear that s   bird as\n",
      "ah eine pfeife   many site\n",
      "erwachsenen nehmen  vomen name\n",
      "this person  a dispersan\n",
      "singing is not   sin so\n",
      "etcetera ich like   a federal in\n",
      "holidays i  holy time\n",
      "brun hair  ruins her\n",
      "on the blackboard   black board\n",
      "the blackbird  black bird\n",
      "school and  school and\n",
      "by myself  penis of\n",
      "slides but slides   slight spotlights\n",
      "fun you  fun you\n",
      "so my superpower   surmised the how\n",
      "argentinia it  or terial\n",
      "whole entire  not i\n",
      "hello my name   loma names\n",
      "basketball yeah  basket baya i\n",
      "washington d  washington d\n",
      "food is  who does\n",
      "always tomato  always tomato\n",
      "her bird it   orbit eat\n",
      "a airplane  an air plane\n",
      "ich sie nicht   avarning the\n",
      "wasn t  was not\n",
      "usa i  u s a\n",
      "don t  do not\n",
      "the went  estevan a\n",
      "den place laufen   din plays love and\n",
      "is lollipops  slowly pole\n",
      "mum is  ma miss\n",
      "theodora she  theodora she\n",
      "sagen den  bog near\n",
      "are this  arent of the\n",
      "wollkna uel  walk noyelle\n",
      "no there is   motor as\n",
      "with spongebob  was pont\n",
      "das no  the snow\n",
      "hello test  lateral to\n",
      "simplest once  a simpletons\n",
      "have done that   and intent\n",
      "food is waffles   fides was\n",
      "wandtafel mit  a bantam\n",
      "ist ist  is this\n",
      "shoes ein  shoe sick\n",
      "are blond  or land\n",
      "lehrerin frau  nearer in from\n",
      "a a spitalwagen   spital walkin ye\n",
      "ra der  state but\n",
      "eisba r  eye per\n",
      "eisba r  ice bear\n",
      "eisba r  ice bear\n",
      "wiesendoma ne  vicente was\n",
      "rather have  weather hap\n",
      "the vanilla chewing   weill achieving\n",
      "keine ahnung  na but\n",
      "walking to  woke into\n",
      "what is  what is\n",
      "why is your   wise you are\n",
      "a ninja  an inch\n",
      "didn t  did not\n",
      "didn t  did not\n",
      "2 vanille  21 ill\n",
      "didn t  did not\n",
      "it has  i passed\n",
      "faster than  fastened in\n",
      "for sure yes   recure s\n",
      "didn t  did not\n",
      "yes i  a sigh\n",
      "strawberries in it   straw berresinso\n",
      "cupcakes yeah  cup cakes yea\n",
      "the clock it   gluck is\n",
      "der vase ist   dervise east\n",
      "so male ist   instrumentally on\n",
      "in switzerland  ins with erland\n",
      "das gibt  a slips\n",
      "a hamburger  hand berger\n",
      "sweep fetch  sleep fitch\n",
      "emotional heights  modeled folkes\n",
      "don t  do not\n",
      "have done  had gone\n",
      "a dog  a dog\n",
      "yuck no  you know\n",
      "a kamin  come in\n",
      "the space  this base\n",
      "don t  do not\n",
      "t i love   will ave\n",
      "you need this   the unit is\n",
      "favorite sport is   favorites for this\n",
      "do not  don t\n",
      "lion are i   lions or if\n",
      "disn t  does not\n",
      "i spy with   ice pond\n",
      "book is  book is\n",
      "grauba one  grow bindon\n",
      "we are sold   was told\n",
      "besser verstecken  sever sicken\n",
      "the switzerland  this witten and\n",
      "a nintendo  an intend to\n",
      "i did  side in\n",
      "the animal  that i am\n",
      "col other  colonel adar\n",
      "it is  of time\n",
      "it starts  the story\n",
      "man is  mans the\n",
      "no it  now the\n",
      "harry potter  a reporter\n",
      "animal are yellow   only of\n",
      "animal can  and milmkill\n",
      "a eisba r   at ice bar\n",
      "a eisba r   ice bear\n",
      "eisba r  ice par\n",
      "some animals  some animals\n",
      "tream fahrzeug  tree spats like\n",
      "a banana  at the nano\n",
      "land animal  london mill\n",
      "this ha  the rota\n",
      "you rather  your retter\n",
      "is the orange   mister arena\n",
      "has brown  a span\n",
      "orange hair  an share\n",
      "on der kaffe   under case\n",
      "pippi langstrump  picketing strum\n",
      "everywhere bo  every wimple\n",
      "wo man  damn and\n",
      "eine katze  a lucas\n",
      "that would  staupy learn\n",
      "in there  in there\n",
      "did not  the edna\n",
      "will be naruto   elvina rot\n",
      "take some  takes of\n",
      "sind wir jetzt   she mentioned\n",
      "am going  also like\n",
      "tuesday i  shoin their\n",
      "was passiert  apple 0\n",
      "okay also  it was\n",
      "fertig und dann   a fact continen\n",
      "grandma is  grand mice\n",
      "wenn ich umfalle   venison pale\n",
      "yes i  ye say\n",
      "yes i  you say\n",
      "dancing and  do not\n",
      "no bombo bombo   bombe bumba\n"
     ]
    }
   ],
   "source": [
    "for s1, s2 in zip(human_words, stt_words):\n",
    "    for w1, w2 in zip(s1, s2):\n",
    "        if len(w1.split()) > 1 and len(w2.split()) > 1:\n",
    "            print(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an lusting\n",
      "kinder wagon\n",
      "towber stop\n",
      "uncap centrum\n",
      "to rift in\n",
      "uncas centrum verse\n",
      "yonkhol sudden\n",
      "iron coups pockets\n",
      "cafe test\n",
      "in what\n",
      "ipl turn\n",
      "if turn\n",
      "singe trent\n",
      "matematic ye\n",
      "open a\n",
      "least cushman this\n",
      "a an\n",
      "be note\n",
      "home fall\n",
      "talk in\n",
      "i fur yes\n",
      "ay and\n",
      "fall in\n",
      "writen with\n",
      "disco coukl\n",
      "for hanging or\n",
      "ladies as\n",
      "was her\n",
      "ice bear\n",
      "ice bear\n",
      "ice bear\n",
      "ice pear\n",
      "ice care\n",
      "short fit\n",
      "on tenden\n",
      "la krits\n",
      "gale la\n",
      "regan tirm\n",
      "leaves to\n",
      "vegas the\n",
      "reference on the\n",
      "such mute\n",
      "up fag\n",
      "back this\n",
      "gift i\n",
      "like see\n",
      "i got\n",
      "for shena\n",
      "what is\n",
      "i stood\n",
      "bridge feel\n",
      "over romped\n",
      "gregson lire\n",
      "be lighting in\n",
      "princess in\n",
      "free seer\n",
      "of nahara\n",
      "no i\n",
      "him a at\n",
      "we feel\n",
      "toe shower\n",
      "eyes were\n",
      "ice pear\n",
      "a sushi\n",
      "p 0\n",
      "on ossano\n",
      "pull over\n",
      "ash bilde\n",
      "winfast north\n",
      "fasbilta ronda\n",
      "it is\n",
      "duncle blow\n",
      "10412 okay\n",
      "for an\n",
      "our otho\n",
      "mettle altar\n",
      "cottonge beele\n",
      "coffer in dren\n",
      "and yes\n",
      "is alternate\n",
      "bomb on\n",
      "body an took\n",
      "body hose\n",
      "body howison\n",
      "both hasten\n",
      "bade an took\n",
      "or ranch order\n",
      "bad motor\n",
      "do the as\n",
      "so and\n",
      "full hung\n",
      "fore hung\n",
      "launch we\n",
      "stagei with\n",
      "advise okay\n",
      "sit ssuck or\n",
      "fore hung\n",
      "sun don\n",
      "kiss n\n",
      "fluke tok\n",
      "giving stand\n",
      "sheet richter\n",
      "many site\n",
      "vomen name\n",
      "the lumps\n",
      "fur verse laugh\n",
      "a federal in\n",
      "m sure\n",
      "on the\n",
      "avarning the\n",
      "u s a\n",
      "the wealth\n",
      "kiss on\n",
      "fern shell\n",
      "fond sahar\n",
      "come in\n",
      "din plays love and\n",
      "vouch hound\n",
      "in brecon\n",
      "up mul\n",
      "bog near\n",
      "let in\n",
      "inter grout\n",
      "walk noyelle\n",
      "4 hung\n",
      "the snow\n",
      "hinter cond\n",
      "a bantam\n",
      "is this\n",
      "me are\n",
      "shoe sick\n",
      "book i live\n",
      "sounder stop\n",
      "nearer in from\n",
      "clydach rock\n",
      "spital walkin ye\n",
      "son brille\n",
      "state but\n",
      "belt carte\n",
      "for her\n",
      "eye per\n",
      "ice bear\n",
      "ice bear\n",
      "pop housen\n",
      "pop housen\n",
      "pop housen\n",
      "you know\n",
      "one bones\n",
      "bung bones\n",
      "citronen cool\n",
      "music books\n",
      "na but\n",
      "sweeter loving\n",
      "comic housing\n",
      "no or\n",
      "ve give\n",
      "the ring\n",
      "in golf\n",
      "dervise east\n",
      "instrumentally on\n",
      "a slips\n",
      "chichen he\n",
      "come in\n",
      "shine h\n",
      "siting instrument\n",
      "son brad\n",
      "woon singer\n",
      "fell to\n",
      "leaps in\n",
      "oko elton\n",
      "bed free\n",
      "social aunt\n",
      "upper stuff\n",
      "a liner\n",
      "sever sicken\n",
      "give ward stock\n",
      "up mohan\n",
      "or shine le\n",
      "stand sagen\n",
      "school fry\n",
      "ca and\n",
      "a m\n",
      "at ice bar\n",
      "ice bear\n",
      "ice par\n",
      "tree spats like\n",
      "duk tyke\n",
      "family known\n",
      "to fife\n",
      "i sow\n",
      "air of\n",
      "nor helen\n",
      "trump bread\n",
      "sprung brit\n",
      "under case\n",
      "picketing strum\n",
      "is it\n",
      "bee yes\n",
      "are in\n",
      "damn and\n",
      "we i\n",
      "a lucas\n",
      "clatter a\n",
      "frog tike\n",
      "she mentioned\n",
      "i go\n",
      "to school\n",
      "we may\n",
      "apple 0\n",
      "well all\n",
      "it was\n",
      "a fact continen\n",
      "gi gangen\n",
      "convert then\n",
      "venison pale\n",
      "i am\n",
      "swim rayther\n",
      "hot site\n",
      "a 2nd door tofa\n"
     ]
    }
   ],
   "source": [
    "for sentence, labels in zip(stt_words, word_classes):\n",
    "    for word, label in zip(sentence, labels):\n",
    "        if len(word.split()) > 1 and label:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few concerns:\n",
    "1. Should we ignore other @ annotations, or can they be useful features for network training?\n",
    "2. Some word entries actually contain multiple words, should we split them? If so, how do we keep the correspondence to the human transcript?\n",
    "3. Do we use the human transcript for anything other than annotation extraction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for entry in data:\n",
    "    for word in entry['words']:\n",
    "        word_list.append(word['human_word'])\n",
    "    \n",
    "characters_after_at = set(char for word in word_list for char in re.findall(r'@(.?)', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!', '?', 'g'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_after_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only characters !, ? or g can be in the annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another way, with feature and word extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    human_words = []  # human-transcribed words\n",
    "    stt_words = []  # STT transcribed words\n",
    "    word_labels = []  # language labels\n",
    "    word_sems = []  # semantical errors\n",
    "    word_grams = []  # grammatical errors\n",
    "\n",
    "    for entry in data:\n",
    "        entry_stt_words = []\n",
    "        entry_hum_words = []\n",
    "        entry_labels = []\n",
    "        entry_grams = []\n",
    "        entry_sems = []\n",
    "\n",
    "        for word in entry[\"words\"]:\n",
    "            humw = word[\"human_word\"]\n",
    "            sttw = word[\"stt_word\"]\n",
    "\n",
    "            for w in sttw.split():\n",
    "                entry_stt_words.append(w)\n",
    "                entry_hum_words.append(humw)\n",
    "                entry_labels.append(\"@g\" in humw)\n",
    "                entry_grams.append(\"@!\" in humw)\n",
    "                entry_sems.append(\"@?\" in humw)\n",
    "\n",
    "        human_words.append(entry_hum_words)\n",
    "        stt_words.append(entry_stt_words)\n",
    "        word_labels.append(entry_labels)\n",
    "        word_grams.append(entry_grams)\n",
    "        word_sems.append(entry_sems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure if we want to use these features, since the classification task is concerned only with STT transcripts, not human-annotated data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
