{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE START\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been split before augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../intermediate_data/translator_basic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'words_higher_perc.pkl'), 'rb') as file:\n",
    "    tr_stt_words = pickle.load(file)\n",
    "with open(os.path.join(data_path, 'labels_higher_perc.pkl'), 'rb') as file:\n",
    "    tr_word_labels = pickle.load(file)\n",
    "\n",
    "tr_stt_transcripts   = [\" \".join(words) for words in tr_stt_words]\n",
    "\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "with open(os.path.join(data_path, 'test_words_higher_perc.pkl'), 'rb') as file:\n",
    "    te_stt_words = pickle.load(file)\n",
    "with open(os.path.join(data_path, 'test_labels_higher_perc.pkl'), 'rb') as file:\n",
    "    te_word_labels = pickle.load(file)\n",
    "\n",
    "te_stt_transcripts   = [\" \".join(words) for words in te_stt_words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyco/EPFL/SEMESTAR_1/ML/ml-project-2-machinesoflearning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_encoder import encode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model_bert.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stt_vectors = []\n",
    "te_stt_vectors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, words in zip(tr_stt_transcripts, tr_stt_words):\n",
    "    tr_stt_vectors.append(\n",
    "        encode_sentence(sentence, words, model_bert, tokenizer)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, words in zip(te_stt_transcripts, te_stt_words):\n",
    "    te_stt_vectors.append(\n",
    "        encode_sentence(sentence, words, model_bert, tokenizer)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tensor       = torch.vstack(tr_stt_vectors)\n",
    "tr_label_tensor = torch.tensor([int(element) for sublist in tr_word_labels for element in sublist])\n",
    "\n",
    "\n",
    "te_tensor = torch.vstack(te_stt_vectors)\n",
    "te_label_tensor = torch.tensor([int(element) for sublist in te_word_labels for element in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP, cross_validate_model, train_model, calc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CUDA accelleration if possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_options = [10, 25, 20]\n",
    "hidden_layers_options = [1, 4, 8, 12, 16]\n",
    "neurons_per_layer_options = [32, 64, 128, 256]\n",
    "learning_rate_options = [1e-3, 1e-4, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = itertools.product(epochs_options, hidden_layers_options, neurons_per_layer_options, learning_rate_options)\n",
    "parameter_combinations = list(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "features = tr_tensor\n",
    "labels = tr_label_tensor\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "german_proportion = tr_label_tensor.to(torch.float).mean()\n",
    "weights = torch.tensor([1/(1-german_proportion), 1/german_proportion])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a temporary array to store intermediate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a grid search for best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [3:08:16<00:00, 62.76s/it]   \n"
     ]
    }
   ],
   "source": [
    "for combination in tqdm(parameter_combinations):\n",
    "    epochs, hidden_layers, neurons_per_layer, learning_rate = combination\n",
    "    \n",
    "    model = MLP(features.shape[1], hidden_layers, neurons_per_layer).to(torch_device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    tr_loss, tr_loss_std, te_loss, te_loss_std = \\\n",
    "        cross_validate_model(model,\n",
    "                             features,\n",
    "                             labels,\n",
    "                             criterion,\n",
    "                             optimizer,\n",
    "                             splitter,\n",
    "                             n_epochs=epochs,\n",
    "                             num_workers=0,\n",
    "                             device=torch_device,\n",
    "                             class_weights=weights\n",
    "        )\n",
    "    \n",
    "    values_to_add = [epochs, hidden_layers, neurons_per_layer, learning_rate,\\\n",
    "        tr_loss, tr_loss_std, te_loss, te_loss_std]\n",
    "\n",
    "    # Add preliminary data to dataframe\n",
    "    grid_search_data.append(values_to_add)\n",
    "\n",
    "    if te_loss < best_loss:\n",
    "        best_loss = te_loss\n",
    "        best_params = combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe to store hyperparameter data and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '.'\n",
    "columns = ['epochs', 'hidden_layers', 'neurons_per_layer', 'learning_rate', 'tr_loss', 'tr_loss_std', 'te_loss', 'te_loss_std']\n",
    "gs_frame = pd.DataFrame(grid_search_data, columns=columns)\n",
    "gs_frame.to_csv(os.path.join(out_path, 'gs_data_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 256, 0.0001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import STTDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the whole dataset with the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = STTDataset(tr_tensor, tr_label_tensor)\n",
    "num_workers = 0  # This works fastest on my machine\n",
    "train_loader = DataLoader(\n",
    "            train_data, batch_size=128, shuffle=True, num_workers=num_workers\n",
    "        )\n",
    "\n",
    "german_proportion = tr_label_tensor.to(torch.float).mean()\n",
    "weights = torch.tensor([1/(1-german_proportion), 1/german_proportion])\n",
    "epochs, hidden_layers, neurons_per_layer, learning_rate = best_params\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "model = MLP(features.shape[1], hidden_layers, neurons_per_layer).to(torch_device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05676008819047448"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, train_loader, n_epochs=epochs, device=torch_device, class_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = STTDataset(te_tensor, te_label_tensor)\n",
    "test_loader = DataLoader(\n",
    "            test_data, batch_size=len(test_data), shuffle=True, num_workers=num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(torch_device), labels.to(torch_device)\n",
    "        pred = model(inputs)\n",
    "        pred = torch.squeeze(pred, dim=1)\n",
    "        loss = criterion(pred, labels.to(torch.float)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = calc_stats(pred, te_label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([[loss, accuracy, precision, recall, f1]],\n",
    "                        columns = ['loss', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "results.to_csv(os.path.join(out_path, 'results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_te_words = [element for sublist in te_stt_words for element in sublist]\n",
    "all_te_labels = [element for sublist in te_word_labels for element in sublist]\n",
    "all_te_predictions = (pred.to('cpu').numpy().flatten() > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_words = []\n",
    "german_predictions = []\n",
    "for i in range(len(all_te_words)):\n",
    "    if all_te_labels[i]:\n",
    "        german_words.append(all_te_words[i])\n",
    "        german_predictions.append(all_te_predictions[i])\n",
    "\n",
    "predicted_labels = pd.DataFrame(\n",
    "    {'word': german_words, 'prediction': german_predictions}\n",
    ")\n",
    "predicted_labels.to_csv(\n",
    "    os.path.join(out_path, 'word_labels.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>so</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>means</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>shading</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>shelton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>makes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>monte</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>was</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>outro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>met</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>howls</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>chrome</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>just</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>im</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>bonbons</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>this</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>at</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>wot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>staaken</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  prediction\n",
       "27        so           1\n",
       "91     means           1\n",
       "157  shading           1\n",
       "62   shelton           1\n",
       "167    makes           1\n",
       "376    monte           1\n",
       "349      was           1\n",
       "295    outro           1\n",
       "294      met           0\n",
       "263    howls           0\n",
       "271      the           0\n",
       "270   chrome           0\n",
       "269     just           0\n",
       "268       im           0\n",
       "267  bonbons           0\n",
       "266     this           0\n",
       "297     auto           0\n",
       "265       at           0\n",
       "264      wot           0\n",
       "262  staaken           0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels.sort_values(by='prediction', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
