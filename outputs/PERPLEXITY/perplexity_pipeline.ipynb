{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import create_word_lists, tidy_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/corpus_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "data = data['records']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_transcripts = [entry['human_transcript'] for entry in data]\n",
    "stt_transcripts   = [entry['stt_transcript'] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_words, stt_words, word_labels, word_grams, word_sems = \\\n",
    "    create_word_lists(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the sentences are too long, so we need to shorten them. The sentences are basically concatenations of individual words with spaces in between, without any interpuction, so they are reconstructed from word lists when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt_transcripts, stt_words, word_labels, word_grams, word_sems = \\\n",
    "    tidy_sentence_length(stt_transcripts, stt_words, word_labels, word_grams, word_sems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE START\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract which sentences contain German words in order to stratify the data split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(map(len, word_labels))\n",
    "padded_labels = [row + [False] * (max_length - len(row)) for row in word_labels]\n",
    "padded_labels = np.array(padded_labels)\n",
    "stat_labels = np.any(padded_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we split only indices and not data itself, because the data contains arrays of variable length, which does not work with `train_test_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(stt_transcripts)))\n",
    "tr_indices, te_indices = train_test_split(indices, test_size=0.2, random_state=0, shuffle=True, stratify=stat_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are hepler functions that will extract data selected by indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_train = itemgetter(*tr_indices)\n",
    "extract_test  = itemgetter(*te_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, do data splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_stt_transcripts   = extract_train(stt_transcripts)\n",
    "tr_stt_words         = extract_train(stt_words)\n",
    "\n",
    "tr_word_labels       = extract_train(word_labels)\n",
    "tr_word_grams        = extract_train(word_grams)\n",
    "tr_word_sems         = extract_train(word_sems)\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "te_stt_transcripts   = extract_test(stt_transcripts)\n",
    "te_stt_words         = extract_test(stt_words)\n",
    "\n",
    "te_word_labels       = extract_test(word_labels)\n",
    "te_word_grams        = extract_test(word_grams)\n",
    "te_word_sems         = extract_test(word_sems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_with_perplexity(\n",
    "    sentence: str,\n",
    "    words: list,\n",
    "    model: BertForMaskedLM,\n",
    "    tokenizer: BertTokenizer,\n",
    "    vectorization: str = \"sum\"\n",
    "):\n",
    "\n",
    "    sentence_ = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "\n",
    "    # Tokenize, extract dictionary ids, and set\n",
    "    # segment ids to 1 (we use outputs/BERT_GRAM/bert_gram_pipeline.ipynbjust 1 sentence)\n",
    "    tokens = tokenizer.tokenize(sentence_)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    segments_ids = [1] * len(tokens)  # The whole text is just one sentence\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # Find token embeddings\n",
    "    with torch.no_grad():  # We aren't doing backprop\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    token_embeddings = torch.stack(outputs.hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)  # We use just 1 sentence\n",
    "    token_embeddings = token_embeddings.permute(1, 0, 2)  # tokens, layers, features\n",
    "    token_embeddings = token_embeddings[1:-1]  # We don't need [CLS] and [SEP]\n",
    "\n",
    "    token_probabilities = torch.squeeze(outputs.logits, dim=0)\n",
    "    token_probabilities = torch.nn.functional.softmax(token_probabilities, dim=-1)\n",
    "    token_perplexities = 2**torch.sum(token_probabilities*torch.log(token_probabilities), dim=-1)\n",
    "\n",
    "    # Choose how to extract vectors from hidden layers\n",
    "    if vectorization == \"sum\":\n",
    "        token_vectors = torch.sum(token_embeddings[:, -4:, :], dim=1)\n",
    "    elif vectorization == \"stl\":\n",
    "        token_vectors = token_embeddings[:, -2, :]\n",
    "    elif vectorization == \"concat\":\n",
    "        token_vectors = torch.cat(\n",
    "            (\n",
    "                token_embeddings[:, -4, :],\n",
    "                token_embeddings[:, -3, :],\n",
    "                token_embeddings[:, -2, :],\n",
    "                token_embeddings[:, -1, :],\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Finally, we need to combine tokens into words,\n",
    "    # as some words were split in tokenization\n",
    "    word_token_lengths = []\n",
    "    for word in words:\n",
    "        word_token_lengths.append(len(tokenizer.encode(word, add_special_tokens=False)))\n",
    "\n",
    "    # Use mean value to combine\n",
    "    tid = 0\n",
    "    word_vectors = []\n",
    "    word_perplexities = []\n",
    "    for wl in word_token_lengths:\n",
    "        word_vectors.append(torch.mean(token_vectors[tid : tid + wl], dim=0))\n",
    "        word_perplexities.append(torch.mean(token_perplexities[tid : tid + wl], dim=0))\n",
    "        tid = tid + wl\n",
    "\n",
    "    return torch.stack(word_vectors), torch.stack(word_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertForMaskedLM.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model_bert.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5434 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5434/5434 [06:14<00:00, 14.51it/s]\n"
     ]
    }
   ],
   "source": [
    "tr_stt_vectors = []\n",
    "tr_stt_perplexities = []\n",
    "\n",
    "for sentence, words in tqdm(zip(tr_stt_transcripts, tr_stt_words), total=len(tr_stt_transcripts)):\n",
    "    word_vectors, word_perplexities = encode_with_perplexity(sentence, words, model_bert, tokenizer)\n",
    "    tr_stt_vectors.append(word_vectors)\n",
    "    tr_stt_perplexities.append(word_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1359 [00:00<03:21,  6.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1359/1359 [01:34<00:00, 14.42it/s]\n"
     ]
    }
   ],
   "source": [
    "te_stt_vectors = []\n",
    "te_stt_perplexities = []\n",
    "\n",
    "for sentence, words in tqdm(zip(te_stt_transcripts, te_stt_words), total=len(te_stt_transcripts)):\n",
    "    word_vectors, word_perplexities = encode_with_perplexity(sentence, words, model_bert, tokenizer)\n",
    "    te_stt_vectors.append(word_vectors)\n",
    "    te_stt_perplexities.append(word_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tensor       = torch.vstack(tr_stt_vectors)\n",
    "tr_label_tensor = torch.tensor([int(element) for sublist in tr_word_labels for element in sublist])\n",
    "tr_grams_tensor = torch.tensor([int(element) for sublist in tr_word_grams  for element in sublist])\n",
    "tr_sems_tensor  = torch.tensor([int(element) for sublist in tr_word_sems   for element in sublist])\n",
    "tr_perps_tensor = torch.cat(tr_stt_perplexities)\n",
    "\n",
    "\n",
    "te_tensor = torch.vstack(te_stt_vectors)\n",
    "te_label_tensor = torch.tensor([int(element) for sublist in te_word_labels for element in sublist])\n",
    "te_grams_tensor = torch.tensor([int(element) for sublist in te_word_grams  for element in sublist])\n",
    "te_sems_tensor  = torch.tensor([int(element) for sublist in te_word_sems   for element in sublist])\n",
    "te_perps_tensor = torch.cat(te_stt_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quicker experimenting, load saved data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP, cross_validate_model, train_model, calc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CUDA accelleration if possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best parameters from the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = (20, 1, 512, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe to store hyperparameter data and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import STTDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the whole dataset with the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = STTDataset(tr_tensor, tr_label_tensor)\n",
    "train_data.add_feature(tr_perps_tensor)\n",
    "num_workers = 0  # This works fastest on my machine\n",
    "train_loader = DataLoader(\n",
    "            train_data, batch_size=128, shuffle=True, num_workers=num_workers\n",
    "        )\n",
    "\n",
    "epochs, hidden_layers, neurons_per_layer, learning_rate = best_params\n",
    "\n",
    "german_proportion = tr_label_tensor.to(torch.float).mean()\n",
    "weights = torch.tensor([1/(1-german_proportion), 1/german_proportion])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "model = MLP(train_data.embeddings.shape[1], hidden_layers, neurons_per_layer).to(torch_device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011104600767240576"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, train_loader, n_epochs=epochs, device=torch_device, class_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = STTDataset(te_tensor, te_label_tensor)\n",
    "test_data.add_feature(te_perps_tensor)\n",
    "test_loader = DataLoader(\n",
    "            test_data, batch_size=len(test_data), shuffle=True, num_workers=num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(torch_device), labels.to(torch_device)\n",
    "        pred = model(inputs)\n",
    "        pred = torch.squeeze(pred, dim=1)\n",
    "        loss = criterion(pred, labels.to(torch.float)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = calc_stats(pred, te_label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01712328767123288"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([[loss, accuracy, precision, recall, f1]],\n",
    "                        columns = ['loss', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "results.to_csv(os.path.join(out_path, 'results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_te_words = [element for sublist in te_stt_words for element in sublist]\n",
    "all_te_labels = [element for sublist in te_word_labels for element in sublist]\n",
    "all_te_predictions = (pred.to('cpu').numpy().flatten() > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_words = []\n",
    "german_predictions = []\n",
    "for i in range(len(all_te_words)):\n",
    "    if all_te_labels[i]:\n",
    "        german_words.append(all_te_words[i])\n",
    "        german_predictions.append(all_te_predictions[i])\n",
    "\n",
    "predicted_labels = pd.DataFrame(\n",
    "    {'word': german_words, 'prediction': german_predictions}\n",
    ")\n",
    "predicted_labels.to_csv(\n",
    "    os.path.join(out_path, 'word_labels.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>princess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>show</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>pale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>we</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>bonbons</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>finest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>walk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>chrome</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>just</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>im</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>this</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>so</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>at</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>wot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>howls</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>staaken</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  prediction\n",
       "145  princess           1\n",
       "283      show           1\n",
       "184       and           1\n",
       "166      pale           1\n",
       "87         we           1\n",
       "0         ash           0\n",
       "267   bonbons           0\n",
       "274    finest           0\n",
       "273      walk           0\n",
       "272       the           0\n",
       "271       the           0\n",
       "270    chrome           0\n",
       "269      just           0\n",
       "268        im           0\n",
       "266      this           0\n",
       "276        so           0\n",
       "265        at           0\n",
       "264       wot           0\n",
       "263     howls           0\n",
       "262   staaken           0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels.sort_values(by='prediction', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
