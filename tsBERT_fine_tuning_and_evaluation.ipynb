{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0077f87f",
   "metadata": {},
   "source": [
    "# Predicting german words using tsBERT (TongueSwitcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375b4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67df4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules import\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed1ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random as rnd\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from data_loading import create_word_lists, tidy_sentence_length\n",
    "from tsBERT_data_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077af35",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0619d",
   "metadata": {},
   "source": [
    "### Loading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44499252",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/corpus_data.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "records = data[\"records\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe5332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_transcripts = [entry[\"human_transcript\"] for entry in records]\n",
    "stt_transcripts = [entry[\"stt_transcript\"] for entry in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6104a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human-transcribed words, STT transcribed words, language labels, semantical errors, grammatical errors\n",
    "human_words, stt_words, word_labels, word_grams, word_sems = create_word_lists(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fbc9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "stt_transcripts, stt_words, labels, word_grams, word_sems = tidy_sentence_length(\n",
    "    stt_transcripts, stt_words, word_labels, word_grams, word_sems\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd8cf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert boolean labels from True to 1 and from False to 0\n",
    "labels = [[1 if label else 0 for label in record_labels] for record_labels in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebf2488",
   "metadata": {},
   "source": [
    "### Loading synthetic dataset augmented with German language elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f276fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/\"\n",
    "\n",
    "# reading the data from the files\n",
    "with open(data_path + \"words_higher_perc.pkl\", \"rb\") as file:\n",
    "    stt_synthetic_words = pickle.load(file)\n",
    "\n",
    "with open(data_path + \"labels_higher_perc.pkl\", \"rb\") as file:\n",
    "    synthetic_labels = pickle.load(file)\n",
    "\n",
    "# convert boolean labels from True to 1 and from False to 0\n",
    "synthetic_labels = [\n",
    "    [1 if label else 0 for label in record_labels] for record_labels in synthetic_labels\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea0698",
   "metadata": {},
   "source": [
    "## Quick Corpus Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af919bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6723 transcripts in total.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(records)} transcripts in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01a46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_per_record = [len(record[\"words\"]) for record in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17d432f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum number of words in any transcript is 1.\n",
      "The maximum number of words in any transcript is 517.\n",
      "The median number of words across all transcripts is 6.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The minimum number of words in any transcript is {min(nb_words_per_record)}.\")\n",
    "print(f\"The maximum number of words in any transcript is {max(nb_words_per_record)}.\")\n",
    "print(\n",
    "    f\"The median number of words across all transcripts is {int(np.median(nb_words_per_record))}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75c4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of word counts\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.displot(nb_words_per_record, orientation=\"horizontal\", height=3, aspect=3)\n",
    "plt.xlim(1, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9249423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62305 words in total out of which only 3.00% are german.\n"
     ]
    }
   ],
   "source": [
    "german_proportion, total_tokens = calculate_label_proportions(word_labels)\n",
    "print(\n",
    "    f\"There are {total_tokens} words in total out of which only {german_proportion*100:.2f}% are german.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d467c",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Data Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3179f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tsBERT model and the tokenizer\n",
    "model_name = \"igorsterner/german-english-code-switching-identification\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84340e",
   "metadata": {},
   "source": [
    "### Transcripts Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9557b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "window_size = 0\n",
    "batch_size = 8\n",
    "max_length = 268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cbe3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the contextual input with labels\n",
    "contextual_stt_input, contextual_labels = create_contextual_input_with_labels(\n",
    "    stt_words, labels, window_size=window_size\n",
    ")\n",
    "(\n",
    "    contextual_stt_synthetic_input,\n",
    "    contextual_synthetic_labels,\n",
    ") = create_contextual_input_with_labels(\n",
    "    stt_synthetic_words, synthetic_labels, window_size=window_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e13acaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the desired total length for BERT embeddings (to make sure they are the same between train-validation-test sets)\n",
    "\n",
    "# tokenize the STT-transcribed transcripts using the BERT tokenizer\n",
    "tokenized_inputs = tokenizer(\n",
    "    contextual_stt_input,\n",
    "    truncation=True,\n",
    "    # padding=True,\n",
    "    padding=\"max_length\",\n",
    "    is_split_into_words=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "tokenized_synthetic_inputs = tokenizer(\n",
    "    contextual_stt_synthetic_input,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    is_split_into_words=True,\n",
    "    max_length=max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b5361",
   "metadata": {},
   "source": [
    "### Label Alignement\n",
    "- we adjust the labels: since we add context (neighbour transcripts) and [SEP] tokens as input the the model, we also also need to adjust out labels to align with the new token structure.\n",
    "- we assign an ignore index (-100) to these separator tokens since they don't carry meaningful language labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eeeab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the labels so that they are suitable for the tsBERT model\n",
    "tsBERT_labels = preprocess_labels(tokenized_inputs, contextual_labels)\n",
    "tsBERT_synthetic_labels = preprocess_labels(\n",
    "    tokenized_synthetic_inputs, contextual_synthetic_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2787f13",
   "metadata": {},
   "source": [
    "## tsBERT Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85e98584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STTDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c172b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 0, Batch size: 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#full_synthetic_loader = DataLoader(full_synthetic_dataset, \u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#                                   batch_size=batch_size, \u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#                                   shuffle=True)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m### tsBERT EVALUATION ###\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindow size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Batch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_results)\n",
      "File \u001b[0;32m~/Documents/Education/Master/ML/project_2/ml-project-2-machinesoflearning/DANAE/tsBERT_data_processing.py:216\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m    213\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# forward pass, get predictions\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m    218\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1760\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1760\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1774\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1019\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1012\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1013\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1014\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1018\u001b[0m )\n\u001b[0;32m-> 1019\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1032\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:609\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    600\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    601\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    602\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    535\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 537\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:550\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    549\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 550\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:462\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 462\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    464\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ada/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "window_sizes = [0, 1, 2, 3, 4]\n",
    "batch_sizes = [8, 16, 3]\n",
    "max_length = 268\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for window_size in window_sizes:\n",
    "        # compute the contextual input with labels\n",
    "        contextual_stt_input, contextual_labels = create_contextual_input_with_labels(\n",
    "            stt_words, labels, window_size=window_size\n",
    "        )\n",
    "        # contextual_stt_synthetic_input, contextual_synthetic_labels = create_contextual_input_with_labels(stt_synthetic_words, synthetic_labels, window_size=window_size)\n",
    "\n",
    "        # tokenize the STT-transcribed transcripts using the BERT tokenizer\n",
    "        tokenized_inputs = tokenizer(\n",
    "            contextual_stt_input,\n",
    "            truncation=True,\n",
    "            # padding=True,\n",
    "            padding=\"max_length\",\n",
    "            is_split_into_words=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "        # align the labels so that they are suitable for the tsBERT model\n",
    "        tsBERT_labels = preprocess_labels(tokenized_inputs, contextual_labels)\n",
    "\n",
    "        # convert the tokenized input and label sets into a format suitable for training (datasets)\n",
    "        full_dataset = STTDataset(tokenized_inputs, tsBERT_labels)\n",
    "        # full_synthetic_dataset = STTDataset(tokenized_synthetic_inputs, tsBERT_synthetic_labels)\n",
    "\n",
    "        # prepare the DataLoaders\n",
    "        full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # full_synthetic_loader = DataLoader(full_synthetic_dataset,\n",
    "        #                                   batch_size=batch_size,\n",
    "        #                                   shuffle=True)\n",
    "\n",
    "        ### tsBERT EVALUATION ###\n",
    "        print(f\"Window size: {window_size}, Batch size: {batch_size}\")\n",
    "        eval_results = evaluate(model, full_loader)\n",
    "        print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510a2b2",
   "metadata": {},
   "source": [
    "## Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fbdf91",
   "metadata": {},
   "source": [
    "### 80-20 Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa5d59",
   "metadata": {},
   "source": [
    "We need to extract which sentences contain German words in order to stratify the data split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5edb649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_labels = [\n",
    "    [True if (label == 1) else False for label in record_labels]\n",
    "    for record_labels in tsBERT_labels\n",
    "]\n",
    "stat_labels = np.any(stat_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13618a",
   "metadata": {},
   "source": [
    "Here, we split only indices and not data itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244d8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(stt_transcripts)))\n",
    "tr_indices, te_indices = train_test_split(\n",
    "    indices, test_size=0.2, random_state=0, shuffle=True, stratify=stat_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f336d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_train = itemgetter(*tr_indices)\n",
    "extract_test = itemgetter(*te_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8648d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_contextual_stt_input = list(extract_train(contextual_stt_input))\n",
    "tr_tsBERT_labels = list(extract_train(tsBERT_labels))\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "te_contextual_stt_input = list(extract_test(contextual_stt_input))\n",
    "te_tsBERT_labels = list(extract_test(tsBERT_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d97f8",
   "metadata": {},
   "source": [
    "### 90-10 Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02c3aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_labels = [\n",
    "    [True if (label == 1) else False for label in record_labels]\n",
    "    for record_labels in tr_tsBERT_labels\n",
    "]\n",
    "stat_labels = np.any(stat_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40d29bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(tr_contextual_stt_input)))\n",
    "tr_indices, val_indices = train_test_split(\n",
    "    indices, test_size=0.1, random_state=0, shuffle=True, stratify=stat_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8473211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_train = itemgetter(*tr_indices)\n",
    "extract_val = itemgetter(*val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba5a29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_val_contextual_stt_input = tr_contextual_stt_input.copy()\n",
    "tr_val_tsBERT_labels = tr_tsBERT_labels.copy()\n",
    "\n",
    "tr_contextual_stt_input = list(extract_train(tr_val_contextual_stt_input))\n",
    "tr_tsBERT_labels = list(extract_train(tr_val_tsBERT_labels))\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "val_contextual_stt_input = list(extract_val(tr_val_contextual_stt_input))\n",
    "val_tsBERT_labels = list(extract_val(tr_val_tsBERT_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29351e4",
   "metadata": {},
   "source": [
    "## tsBERT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf388a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the desired total length for BERT embeddings (to make sure they are the same between train-validation-test sets)\n",
    "train_inputs = tokenizer(\n",
    "    tr_contextual_stt_input,\n",
    "    truncation=True,\n",
    "    # padding=True,\n",
    "    padding=\"max_length\",\n",
    "    is_split_into_words=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "validation_inputs = tokenizer(\n",
    "    val_contextual_stt_input,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    is_split_into_words=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "test_inputs = tokenizer(\n",
    "    te_contextual_stt_input,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    is_split_into_words=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "train_labels = tr_tsBERT_labels\n",
    "validation_labels = val_tsBERT_labels\n",
    "test_labels = te_tsBERT_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64582dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the tokenized input and label sets into a format suitable for training (datasets)\n",
    "train_dataset = STTDataset(train_inputs, train_labels)\n",
    "validation_dataset = STTDataset(validation_inputs, validation_labels)\n",
    "test_dataset = STTDataset(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "909170db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter grid\n",
    "learning_rates = [5e-5, 3e-5, 3e-5]  # BERT authors recommend 3e-4, 1e-4, 5e-5, 3e-5\n",
    "batch_sizes = [16, 32]  # BERT authors recommend 8, 16, 32, 64, 128\n",
    "num_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb34f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 3/306 [00:19<33:15,  6.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# storage for all model results\n",
    "all_results = []\n",
    "\n",
    "# hyperparameter Tuning Loop\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        # initialize model\n",
    "        model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "        # GPU Acceleration\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "\n",
    "        # initialize optimizer and loss function for each combination\n",
    "        optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        loss_function = CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "        # prepare the DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "        # train and validate the model\n",
    "        results = train_and_validate(\n",
    "            model,\n",
    "            train_loader,\n",
    "            validation_loader,\n",
    "            num_epochs,\n",
    "            optimizer,\n",
    "            loss_function,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        # store results\n",
    "        all_results.append([lr, batch_size, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list of results to a pandas DataFrame\n",
    "all_results_df = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\n",
    "            \"learning_rate\": lr,\n",
    "            \"batch_size\": bs,\n",
    "            \"epoch\": r[\"epoch\"],\n",
    "            \"train_loss\": r[\"avg_train_loss\"],\n",
    "            \"val_loss\": r[\"avg_test_loss\"],\n",
    "            \"val_accuracy\": r[\"accuracy\"],\n",
    "            \"val_precision\": r[\"precision\"],\n",
    "            \"val_recall\": r[\"recall\"],\n",
    "            \"val_f1\": r[\"f1\"],\n",
    "        }\n",
    "        for lr, bs, result_list in all_results\n",
    "        for r in result_list\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save to CSV\n",
    "all_results_df.to_csv(\"../data/\" + output_filename + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958eedf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25714a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a45c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d72e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
